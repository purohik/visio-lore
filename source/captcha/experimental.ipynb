{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411ea576-e904-472b-a99c-a4abb981f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66e97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_DICT = {\n",
    "            'a': 0,\n",
    "            'f': 1,\n",
    "            'e': 2,\n",
    "            'c': 3,\n",
    "            'b': 4,\n",
    "            'h': 5,\n",
    "            'v': 6,\n",
    "            'z': 7,\n",
    "            '2': 8,\n",
    "            'x': 9,\n",
    "            'g': 10,\n",
    "            'm': 11,\n",
    "            'r': 12,\n",
    "            'u': 13,\n",
    "            'p': 14,\n",
    "            's': 15,\n",
    "            'd': 16,\n",
    "            'n': 17,\n",
    "            '6': 18,\n",
    "            'k': 19,\n",
    "            't': 20\n",
    "            }\n",
    "\n",
    "DECODING_DICT = {\n",
    "            0: 'a',\n",
    "            1: 'f',\n",
    "            2: 'e',\n",
    "            3: 'c',\n",
    "            4: 'b',\n",
    "            5: 'h',\n",
    "            6: 'v',\n",
    "            7: 'z',\n",
    "            8: '2',\n",
    "            9: 'x',\n",
    "            10: 'g',\n",
    "            11: 'm',\n",
    "            12: 'r',\n",
    "            13: 'u',\n",
    "            14: 'p',\n",
    "            15: 's',\n",
    "            16: 'd',\n",
    "            17: 'n',\n",
    "            18: '6',\n",
    "            19: 'k',\n",
    "            20: 't'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d836ad46-0f92-45c1-a468-f99e38a468ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagepath_to_captcha(imagepath):\n",
    "    return imagepath.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "def to_onehot(captcha):\n",
    "    label = np.zeros((len(captcha), len(ENCODING_DICT)))\n",
    "    for index, char in enumerate(captcha):\n",
    "        label[index, ENCODING_DICT[char]] = 1\n",
    "    return tf.convert_to_tensor(label, tf.float32)\n",
    "    # return tf.reshape(tf.convert_to_tensor(label, tf.float32), [-1])\n",
    "\n",
    "def captcha_from_onehot(tensor):\n",
    "    label = []\n",
    "    for index in tf.argmax(tensor, 1).numpy():\n",
    "        label.append(DECODING_DICT[index])\n",
    "    return \"\".join(label)\n",
    "\n",
    "# Instead of one hot, if we directly use the labels, the label becomes of size 6.\n",
    "def to_labels(captcha):\n",
    "    label = np.zeros(len(captcha))\n",
    "    for index, char in enumerate(captcha):\n",
    "        label[index] = ENCODING_DICT[char]\n",
    "    return tf.convert_to_tensor(label, tf.float32)\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    filenames = os.listdir(filepath)\n",
    "    x, y = [], []\n",
    "    for file in filenames:\n",
    "        imagepath = filepath + \"/\" + file\n",
    "        image = tf.io.read_file(imagepath)\n",
    "        image = tf.image.decode_image(image)\n",
    "        pixels = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        # To show images: \n",
    "        # plt.imshow(tf.reshape(pixels, image.shape))\n",
    "        # plt.title('Image as Pixels')\n",
    "        # plt.show()\n",
    "        x.append(pixels)\n",
    "        captcha = imagepath_to_captcha(file).lower()\n",
    "        y.append(to_onehot(captcha))\n",
    "    return (tf.convert_to_tensor(x, tf.float32), tf.convert_to_tensor(y, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02ee90-266a-4262-aff6-a9990451348c",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e462d9-3196-4738-a861-f30fb904d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape: (8501, 50, 250, 3)\n",
      "Training output shape: (8501, 6, 21)\n",
      "Testing input shape: (1500, 50, 250, 3)\n",
      "Testing output shape: (1500, 6, 21)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_dataset(\"dataset/train\")\n",
    "test_x, test_y = load_dataset(\"dataset/test\")\n",
    "\n",
    "input_shape = train_x[0].shape\n",
    "output_shape = train_y[0].shape\n",
    "\n",
    "print(\"Training input shape:\", train_x.shape)\n",
    "print(\"Training output shape:\", train_y.shape)\n",
    "print(\"Testing input shape:\", test_x.shape)\n",
    "print(\"Testing output shape:\", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c426b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_layers(inputs: keras.layers.Input):\n",
    "    inputs = keras.applications.resnet.preprocess_input(inputs)\n",
    "    feature_extractor = keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "    )(inputs)\n",
    "    return feature_extractor\n",
    "\n",
    "def get_classification_layers(inputs: keras.layers.Input):\n",
    "    x = keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = keras.layers.Dense(126, activation='softmax')(x)\n",
    "    x = keras.layers.Reshape(output_shape)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def final_model(inputs):\n",
    "    feature_extractor = get_feature_layers(inputs)\n",
    "    classification_layers = get_classification_layers(feature_extractor)\n",
    "    return classification_layers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986d14cc-b514-4095-9b26-8cc79b9c9a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 250, 3)]      0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (  (None, 50, 250, 3)        0         \n",
      " SlicingOpLambda)                                                \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda  (None, 50, 250, 3)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 2, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 126)               64638     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 6, 21)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26275326 (100.23 MB)\n",
      "Trainable params: 26222206 (100.03 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=input_shape)\n",
    "output = final_model(inputs)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b737ab-8b39-4b2f-b5fc-ff12fe6feeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# graphwiz doesn't install on gLinux ffs.\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05fd070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "266/266 [==============================] - 167s 585ms/step - loss: 2.9806 - accuracy: 0.0670\n",
      "Epoch 2/50\n",
      "266/266 [==============================] - 152s 571ms/step - loss: 2.4472 - accuracy: 0.1661\n",
      "Epoch 3/50\n",
      "266/266 [==============================] - 155s 581ms/step - loss: 1.5181 - accuracy: 0.4355\n",
      "Epoch 4/50\n",
      "266/266 [==============================] - 153s 576ms/step - loss: 0.7359 - accuracy: 0.7295\n",
      "Epoch 5/50\n",
      "266/266 [==============================] - 150s 566ms/step - loss: 0.3867 - accuracy: 0.8743\n",
      "Epoch 6/50\n",
      "266/266 [==============================] - 151s 566ms/step - loss: 0.2401 - accuracy: 0.9370\n",
      "Epoch 7/50\n",
      "266/266 [==============================] - 150s 565ms/step - loss: 0.1506 - accuracy: 0.9657\n",
      "Epoch 8/50\n",
      "266/266 [==============================] - 151s 566ms/step - loss: 0.1196 - accuracy: 0.9729\n",
      "Epoch 9/50\n",
      "266/266 [==============================] - 149s 560ms/step - loss: 0.1025 - accuracy: 0.9750\n",
      "Epoch 10/50\n",
      "266/266 [==============================] - 151s 566ms/step - loss: 0.0842 - accuracy: 0.9795\n",
      "Epoch 11/50\n",
      "266/266 [==============================] - 149s 562ms/step - loss: 0.0775 - accuracy: 0.9798\n",
      "Epoch 12/50\n",
      "266/266 [==============================] - 150s 565ms/step - loss: 0.0735 - accuracy: 0.9813\n",
      "Epoch 13/50\n",
      "266/266 [==============================] - 151s 567ms/step - loss: 0.0786 - accuracy: 0.9801\n",
      "{'loss': [2.9806342124938965, 2.447199583053589, 1.5181081295013428, 0.7359229326248169, 0.38669854402542114, 0.240092471241951, 0.1505930870771408, 0.11962655186653137, 0.1025000512599945, 0.08418072760105133, 0.07753480225801468, 0.0735083520412445, 0.07856258004903793], 'accuracy': [0.066972516477108, 0.16609810292720795, 0.43547818064689636, 0.7294828295707703, 0.8743284940719604, 0.9370270371437073, 0.9656510949134827, 0.9729443788528442, 0.9750421643257141, 0.9795122146606445, 0.9798455238342285, 0.9812766909599304, 0.9800611734390259]}\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor = 'loss', \n",
    "                                           patience = 1, \n",
    "                                           restore_best_weights = True)]\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    epochs = 50,\n",
    "                    callbacks = callbacks)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3602e777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 7s 129ms/step - loss: 6.1134 - accuracy: 0.0473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.113442897796631, 0.047333333641290665]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
